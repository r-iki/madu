"""
ML model storage manager for handling ML models in Cloudflare R2 storage
with optional local fallback
"""
import os
import io
import boto3
from django.conf import settings
import logging

logger = logging.getLogger(__name__)

class ModelStorageManager:
    """
    Wrapper class for handling ML model storage primarily in Cloudflare R2 cloud storage
    with optional local filesystem fallback
    """
    def __init__(self):
        """Initialize the model storage manager"""
        # Define local model directory (only used as fallback)
        self.local_model_dir = os.path.join(settings.BASE_DIR, "ml", "saved_models")
        os.makedirs(self.local_model_dir, exist_ok=True)
        
        # Initialize with default values
        self.use_r2 = False
        self.s3_client = None
        self.bucket_name = None
        
        # By default, use cloud-only mode (no local download)
        self.cloud_only = os.environ.get("ML_CLOUD_ONLY", "true").lower() == "true"
        
        # Detect if running on Heroku
        self.is_heroku = "DYNO" in os.environ
        if self.is_heroku:
            self.cloud_only = True  # Force cloud-only on Heroku
            logger.info("Detected Heroku environment. Using cloud-only storage for ML models.")
        
        # Check if Cloudflare R2 configuration is available
        try:
            # Check if we have the necessary settings
            if hasattr(settings, "CLOUDFLARE_R2_BUCKET") and \
               hasattr(settings, "CLOUDFLARE_R2_ACCESS_KEY") and \
               hasattr(settings, "CLOUDFLARE_R2_SECRET_KEY") and \
               hasattr(settings, "CLOUDFLARE_R2_BUCKET_ENDPOINT"):
                
                self.use_r2 = True
                self.bucket_name = settings.CLOUDFLARE_R2_BUCKET
                
                logger.info(f"Cloud storage enabled for ML models. {'Cloud-only mode' if self.cloud_only else 'Using local fallback if needed'}.")
                self._init_r2_client()
            else:
                if self.cloud_only:
                    logger.error("Cloud-only mode is enabled but Cloudflare R2 settings are missing!")
                logger.warning("Cloudflare R2 settings not found. Using local storage only.")
        except Exception as e:
            logger.error(f"Error initializing R2 storage: {e}")
            self.use_r2 = False
    
    def _init_r2_client(self):
        """Initialize the Cloudflare R2 client"""
        try:
            self.s3_client = boto3.client(
                "s3",
                aws_access_key_id=settings.CLOUDFLARE_R2_ACCESS_KEY,
                aws_secret_access_key=settings.CLOUDFLARE_R2_SECRET_KEY,
                endpoint_url=settings.CLOUDFLARE_R2_BUCKET_ENDPOINT,
            )
            logger.info("Successfully initialized cloud storage client")
        except Exception as e:
            logger.error(f"Failed to initialize S3 client: {e}")
            self.use_r2 = False
    
    def _get_r2_key(self, filename):
        """Convert a filename to an R2 key"""
        return f"ml_models/{os.path.basename(filename)}"
    
    def file_exists(self, filename):
        """Check if a model file exists in the appropriate storage"""
        # Always check cloud storage first if enabled
        if self.use_r2 and self.s3_client:
            try:
                key = self._get_r2_key(filename)
                self.s3_client.head_object(Bucket=self.bucket_name, Key=key)
                return True
            except Exception:
                if self.cloud_only:
                    return False
        
        # Only check local if cloud-only mode is disabled
        if not self.cloud_only:
            local_path = os.path.join(self.local_model_dir, os.path.basename(filename))
            return os.path.exists(local_path)
            
        return False
    
    def get_filepath(self, filename):
        """Get the full path to a model file (for local storage only)"""
        # In cloud-only mode, this doesn't make sense but return a path anyway
        return os.path.join(self.local_model_dir, os.path.basename(filename))
    
    def load_file(self, filename, loader_func):
        """
        Load a model file from storage using the provided loader function
        
        Args:
            filename (str): Name of the model file
            loader_func (callable): Function to load the model (e.g., joblib.load)
            
        Returns:
            The loaded model or None if file not found
        """
        # Always try cloud storage first if enabled
        if self.use_r2 and self.s3_client:
            logger.info(f"Loading {filename} directly from cloud storage...")
            try:
                # Load directly from R2
                key = self._get_r2_key(filename)
                response = self.s3_client.get_object(Bucket=self.bucket_name, Key=key)
                file_content = response["Body"].read()
                
                # Load from bytes buffer
                buffer = io.BytesIO(file_content)
                
                # If not cloud-only mode, also save locally for future use
                if not self.cloud_only:
                    try:
                        local_path = os.path.join(self.local_model_dir, os.path.basename(filename))
                        with open(local_path, "wb") as f:
                            f.write(file_content)
                        logger.info(f"Saved local copy of {filename} from cloud")
                    except Exception as e:
                        logger.warning(f"Failed to save local copy of {filename}: {e}")
                
                return loader_func(buffer)
                
            except Exception as e:
                logger.error(f"Error loading from cloud storage: {str(e)}")
                # In cloud-only mode, don't fall back to local
                if self.cloud_only:
                    logger.error(f"Cloud-only mode is enabled and cloud storage failed - cannot load model")
                    return None
        
        # Only try local storage if cloud-only mode is disabled
        if not self.cloud_only:
            local_path = os.path.join(self.local_model_dir, os.path.basename(filename))
            if os.path.exists(local_path):
                try:
                    model = loader_func(local_path)
                    logger.info(f"Successfully loaded {filename} from local storage")
                    return model
                except Exception as e:
                    logger.error(f"Error loading local file {filename}: {e}")
        
        # If we reach here, we could not load the model
        if self.cloud_only:
            logger.warning(f"File {filename} not found in cloud storage and cloud-only mode is enabled")
        else:
            logger.warning(f"File {filename} not found in any storage location")
        
        return None
    
    def save_file(self, model_obj, filename, saver_func):
        """
        Save a model file to storage using the provided saver function
        
        Args:
            model_obj: The model object to save
            filename (str): Name of the model file
            saver_func (callable): Function to save the model (e.g., joblib.dump)
            
        Returns:
            bool: True if successful, False otherwise
        """
        local_path = os.path.join(self.local_model_dir, os.path.basename(filename))
        
        try:
            # In cloud-only mode, save to a temporary file first
            if self.cloud_only:
                # Use BytesIO to avoid writing to disk
                buffer = io.BytesIO()
                saver_func(model_obj, buffer)
                buffer.seek(0)
                
                # Upload directly to cloud
                if self.use_r2 and self.s3_client:
                    try:
                        logger.info(f"Uploading {filename} directly to cloud storage...")
                        key = self._get_r2_key(filename)
                        self.s3_client.upload_fileobj(
                            buffer,
                            self.bucket_name,
                            key,
                            ExtraArgs={"ContentType": "application/octet-stream"}
                        )
                        logger.info(f"Successfully uploaded {filename} to cloud storage")
                        return True
                    except Exception as e:
                        logger.error(f"Error uploading to cloud: {e}")
                        return False
            else:
                # Save locally
                saver_func(model_obj, local_path)
                logger.info(f"Saved {filename} to local storage")
                
                # If using R2, also upload to R2
                if self.use_r2 and self.s3_client:
                    try:
                        logger.info(f"Uploading {filename} to cloud storage...")
                        key = self._get_r2_key(filename)
                        with open(local_path, "rb") as file_data:
                            self.s3_client.upload_fileobj(
                                file_data,
                                self.bucket_name,
                                key,
                                ExtraArgs={"ContentType": "application/octet-stream"}
                            )
                        logger.info(f"Successfully uploaded {filename} to cloud storage")
                    except Exception as e:
                        logger.error(f"Error uploading to cloud: {e}")
                
                return True
            
        except Exception as e:
            logger.error(f"Error saving model {filename}: {str(e)}")
            return False
