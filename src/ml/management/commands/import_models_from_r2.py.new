from django.core.management.base import BaseCommand
from django.conf import settings
import os
import boto3
import io
import time
import logging

logger = logging.getLogger(__name__)

# Try to import joblib, with a fallback to pickle
try:
    import joblib
except ImportError:
    import pickle as joblib
    logger.warning("joblib not found, using pickle as fallback")

class Command(BaseCommand):
    help = 'Import ML model files from Cloudflare R2 storage to local filesystem'

    def add_arguments(self, parser):
        parser.add_argument(
            '--retry',
            type=int,
            default=3,
            help='Number of retries for failed downloads',
        )
        parser.add_argument(
            '--force',
            action='store_true',
            help='Force download even if local file exists',
        )
        parser.add_argument(
            '--verify',
            action='store_true',
            help='Verify downloaded files by attempting to load them',
        )

    def handle(self, *args, **options):
        # Directory where models should be stored locally
        model_dir = os.path.join(settings.BASE_DIR, 'ml', 'saved_models')
        os.makedirs(model_dir, exist_ok=True)
        
        # Initialize R2 client
        try:
            s3_client = boto3.client(
                's3',
                aws_access_key_id=settings.CLOUDFLARE_R2_ACCESS_KEY,
                aws_secret_access_key=settings.CLOUDFLARE_R2_SECRET_KEY,
                endpoint_url=settings.CLOUDFLARE_R2_BUCKET_ENDPOINT,
            )
            bucket_name = settings.CLOUDFLARE_R2_BUCKET
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"Failed to initialize R2 client: {e}"))
            return
        
        # Count processed files
        success_count = 0
        error_count = 0
        
        try:
            # Make sure our critical models are always included
            required_models = ['scaler.pkl', 'label_encoder.pkl', 'rf_model.pkl', 'svm_model.pkl', 'ann_model.pkl']
            
            # List all objects in the ml_models directory
            self.stdout.write("Listing models in R2 storage...")
            response = s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix='ml_models/'
            )
            
            if 'Contents' not in response:
                self.stdout.write(self.style.WARNING('No models found in R2 storage.'))
                return
            
            # Filter out directories and get just the file objects
            model_files = [obj for obj in response['Contents'] if not obj['Key'].endswith('/')]
            self.stdout.write(f"Found {len(model_files)} model files in R2 storage.")
            
            # Check if our required models are in the list
            found_models = [os.path.basename(obj['Key']) for obj in model_files]
            missing_models = [model for model in required_models if model not in found_models]
            
            if missing_models:
                self.stdout.write(self.style.WARNING(f"Missing required models in R2: {', '.join(missing_models)}"))
            
            # Process each model file
            for obj in model_files:
                key = obj['Key']
                filename = os.path.basename(key)
                if not filename:  # Skip directories
                    continue
                    
                local_path = os.path.join(model_dir, filename)
                
                # Skip if file exists locally and --force is not specified
                if os.path.exists(local_path) and not options['force']:
                    self.stdout.write(f"Skipping {filename}: already exists locally. Use --force to overwrite.")
                    continue
                
                # Try multiple times with retries
                max_retries = options['retry']
                for attempt in range(max_retries):
                    try:
                        self.stdout.write(f"Downloading {filename} from R2 storage (attempt {attempt + 1}/{max_retries})...")
                        
                        # Download the file
                        s3_client.download_file(bucket_name, key, local_path)
                        
                        # Verify the file was downloaded correctly
                        if os.path.exists(local_path):
                            if options['verify']:
                                try:
                                    # Try to load the file to verify it's valid
                                    joblib.load(local_path)
                                    self.stdout.write(self.style.SUCCESS(f"Verified {filename} successfully."))
                                except Exception as ve:
                                    self.stdout.write(self.style.ERROR(f"File verification failed for {filename}: {ve}"))
                                    raise ve
                            
                            success_count += 1
                            self.stdout.write(self.style.SUCCESS(f"Successfully downloaded {filename} to {local_path}"))
                            break  # Success, exit retry loop
                            
                    except Exception as e:
                        self.stdout.write(self.style.WARNING(
                            f"Attempt {attempt + 1}/{max_retries} failed for {filename}: {str(e)}"
                        ))
                        
                        if attempt < max_retries - 1:
                            self.stdout.write(f"Retrying in 2 seconds...")
                            time.sleep(2)  # Wait before retrying
                        else:
                            error_count += 1
                            self.stdout.write(self.style.ERROR(f"Failed to download {filename} after {max_retries} attempts."))
        
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"Error listing objects in R2 storage: {str(e)}"))
            
        # Summary
        self.stdout.write("\nSummary:")
        self.stdout.write(f"Successfully downloaded {success_count} model files.")
        
        if error_count > 0:
            self.stdout.write(self.style.ERROR(f"Failed to download {error_count} model files."))
        
        self.stdout.write(self.style.SUCCESS("Done!"))
